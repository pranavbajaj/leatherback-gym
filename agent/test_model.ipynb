{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115b6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy \n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "# from drive_agent import *\n",
    "from memeory import * \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.distributions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4d09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_img = torch.rand((4, 3, 256, 256), dtype = torch.float32).to(device)\n",
    "obs_steer = torch.rand((4), dtype = torch.float32).to(device)\n",
    "obs_vel = torch.rand((4), dtype = torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078e4249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 256])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a69e582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_buffer = EnvObsMemoryBuffer(obs_img.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e366c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_buffer.add(obs_img, obs_steer, obs_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45824f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_buffer.reset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05dda313",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_buffer.add(obs_img, obs_steer, obs_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac98c265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[0.0803, 0.1891, 0.7614,  ..., 0.5978, 0.7950, 0.2823],\n",
       "           [0.3260, 0.0169, 0.6244,  ..., 0.3864, 0.2245, 0.1055],\n",
       "           [0.4495, 0.3671, 0.2508,  ..., 0.4769, 0.7892, 0.2572],\n",
       "           ...,\n",
       "           [0.9069, 0.5122, 0.7206,  ..., 0.7695, 0.3609, 0.2911],\n",
       "           [0.2999, 0.2628, 0.7753,  ..., 0.8732, 0.3612, 0.8840],\n",
       "           [0.1068, 0.3117, 0.1574,  ..., 0.0846, 0.4768, 0.1771]],\n",
       "  \n",
       "          [[0.7517, 0.5101, 0.2193,  ..., 0.5302, 0.0989, 0.1570],\n",
       "           [0.8966, 0.8926, 0.6566,  ..., 0.6782, 0.4622, 0.3209],\n",
       "           [0.4479, 0.2927, 0.5717,  ..., 0.6245, 0.9125, 0.8210],\n",
       "           ...,\n",
       "           [0.6782, 0.5140, 0.6329,  ..., 0.0036, 0.4603, 0.0529],\n",
       "           [0.9393, 0.6093, 0.7451,  ..., 0.2792, 0.4611, 0.3403],\n",
       "           [0.8585, 0.0732, 0.4531,  ..., 0.4506, 0.2752, 0.0927]],\n",
       "  \n",
       "          [[0.3948, 0.1057, 0.0674,  ..., 0.0272, 0.3122, 0.0587],\n",
       "           [0.9871, 0.1516, 0.2866,  ..., 0.9215, 0.7038, 0.7332],\n",
       "           [0.5372, 0.3536, 0.5692,  ..., 0.7469, 0.3854, 0.6464],\n",
       "           ...,\n",
       "           [0.8008, 0.6308, 0.6592,  ..., 0.5793, 0.0922, 0.0696],\n",
       "           [0.4736, 0.5501, 0.5461,  ..., 0.5054, 0.4197, 0.6733],\n",
       "           [0.0673, 0.8235, 0.3314,  ..., 0.0222, 0.9173, 0.8273]]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[[0.0803, 0.1891, 0.7614,  ..., 0.5978, 0.7950, 0.2823],\n",
       "           [0.3260, 0.0169, 0.6244,  ..., 0.3864, 0.2245, 0.1055],\n",
       "           [0.4495, 0.3671, 0.2508,  ..., 0.4769, 0.7892, 0.2572],\n",
       "           ...,\n",
       "           [0.9069, 0.5122, 0.7206,  ..., 0.7695, 0.3609, 0.2911],\n",
       "           [0.2999, 0.2628, 0.7753,  ..., 0.8732, 0.3612, 0.8840],\n",
       "           [0.1068, 0.3117, 0.1574,  ..., 0.0846, 0.4768, 0.1771]],\n",
       "  \n",
       "          [[0.7517, 0.5101, 0.2193,  ..., 0.5302, 0.0989, 0.1570],\n",
       "           [0.8966, 0.8926, 0.6566,  ..., 0.6782, 0.4622, 0.3209],\n",
       "           [0.4479, 0.2927, 0.5717,  ..., 0.6245, 0.9125, 0.8210],\n",
       "           ...,\n",
       "           [0.6782, 0.5140, 0.6329,  ..., 0.0036, 0.4603, 0.0529],\n",
       "           [0.9393, 0.6093, 0.7451,  ..., 0.2792, 0.4611, 0.3403],\n",
       "           [0.8585, 0.0732, 0.4531,  ..., 0.4506, 0.2752, 0.0927]],\n",
       "  \n",
       "          [[0.3948, 0.1057, 0.0674,  ..., 0.0272, 0.3122, 0.0587],\n",
       "           [0.9871, 0.1516, 0.2866,  ..., 0.9215, 0.7038, 0.7332],\n",
       "           [0.5372, 0.3536, 0.5692,  ..., 0.7469, 0.3854, 0.6464],\n",
       "           ...,\n",
       "           [0.8008, 0.6308, 0.6592,  ..., 0.5793, 0.0922, 0.0696],\n",
       "           [0.4736, 0.5501, 0.5461,  ..., 0.5054, 0.4197, 0.6733],\n",
       "           [0.0673, 0.8235, 0.3314,  ..., 0.0222, 0.9173, 0.8273]]],\n",
       "         device='cuda:0')],\n",
       " [tensor(0.2304, device='cuda:0'), tensor(0.2304, device='cuda:0')],\n",
       " [tensor(0.3213, device='cuda:0'), tensor(0.3213, device='cuda:0')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_buffer.get(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb2b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b033c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False | True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aae4e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Categorical(torch.tensor([[0.4,0.6],[0.5,0.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75279259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(m.sample()[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "698ccd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9163, -0.6931])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.log_prob(m.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7aa6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agenetNetwork = AgentNNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f306ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.ones([4,3,240,320])\n",
    "s = torch.rand((4,1))\n",
    "v = torch.rand((4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d4d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = agenetNetwork(img, s, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e906da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4786, 0.4607],\n",
       "        [0.4785, 0.4609],\n",
       "        [0.4786, 0.4609],\n",
       "        [0.4784, 0.4610]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b7ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. 0 resnet.conv1.weight\n",
      "NO. 1 resnet.bn1.weight\n",
      "NO. 2 resnet.bn1.bias\n",
      "NO. 3 resnet.layer1.0.conv1.weight\n",
      "NO. 4 resnet.layer1.0.bn1.weight\n",
      "NO. 5 resnet.layer1.0.bn1.bias\n",
      "NO. 6 resnet.layer1.0.conv2.weight\n",
      "NO. 7 resnet.layer1.0.bn2.weight\n",
      "NO. 8 resnet.layer1.0.bn2.bias\n",
      "NO. 9 resnet.layer1.1.conv1.weight\n",
      "NO. 10 resnet.layer1.1.bn1.weight\n",
      "NO. 11 resnet.layer1.1.bn1.bias\n",
      "NO. 12 resnet.layer1.1.conv2.weight\n",
      "NO. 13 resnet.layer1.1.bn2.weight\n",
      "NO. 14 resnet.layer1.1.bn2.bias\n",
      "NO. 15 resnet.layer2.0.conv1.weight\n",
      "NO. 16 resnet.layer2.0.bn1.weight\n",
      "NO. 17 resnet.layer2.0.bn1.bias\n",
      "NO. 18 resnet.layer2.0.conv2.weight\n",
      "NO. 19 resnet.layer2.0.bn2.weight\n",
      "NO. 20 resnet.layer2.0.bn2.bias\n",
      "NO. 21 resnet.layer2.0.downsample.0.weight\n",
      "NO. 22 resnet.layer2.0.downsample.1.weight\n",
      "NO. 23 resnet.layer2.0.downsample.1.bias\n",
      "NO. 24 resnet.layer2.1.conv1.weight\n",
      "NO. 25 resnet.layer2.1.bn1.weight\n",
      "NO. 26 resnet.layer2.1.bn1.bias\n",
      "NO. 27 resnet.layer2.1.conv2.weight\n",
      "NO. 28 resnet.layer2.1.bn2.weight\n",
      "NO. 29 resnet.layer2.1.bn2.bias\n",
      "NO. 30 resnet.layer3.0.conv1.weight\n",
      "NO. 31 resnet.layer3.0.bn1.weight\n",
      "NO. 32 resnet.layer3.0.bn1.bias\n",
      "NO. 33 resnet.layer3.0.conv2.weight\n",
      "NO. 34 resnet.layer3.0.bn2.weight\n",
      "NO. 35 resnet.layer3.0.bn2.bias\n",
      "NO. 36 resnet.layer3.0.downsample.0.weight\n",
      "NO. 37 resnet.layer3.0.downsample.1.weight\n",
      "NO. 38 resnet.layer3.0.downsample.1.bias\n",
      "NO. 39 resnet.layer3.1.conv1.weight\n",
      "NO. 40 resnet.layer3.1.bn1.weight\n",
      "NO. 41 resnet.layer3.1.bn1.bias\n",
      "NO. 42 resnet.layer3.1.conv2.weight\n",
      "NO. 43 resnet.layer3.1.bn2.weight\n",
      "NO. 44 resnet.layer3.1.bn2.bias\n",
      "NO. 45 resnet.layer4.0.conv1.weight\n",
      "NO. 46 resnet.layer4.0.bn1.weight\n",
      "NO. 47 resnet.layer4.0.bn1.bias\n",
      "NO. 48 resnet.layer4.0.conv2.weight\n",
      "NO. 49 resnet.layer4.0.bn2.weight\n",
      "NO. 50 resnet.layer4.0.bn2.bias\n",
      "NO. 51 resnet.layer4.0.downsample.0.weight\n",
      "NO. 52 resnet.layer4.0.downsample.1.weight\n",
      "NO. 53 resnet.layer4.0.downsample.1.bias\n",
      "NO. 54 resnet.layer4.1.conv1.weight\n",
      "NO. 55 resnet.layer4.1.bn1.weight\n",
      "NO. 56 resnet.layer4.1.bn1.bias\n",
      "NO. 57 resnet.layer4.1.conv2.weight\n",
      "NO. 58 resnet.layer4.1.bn2.weight\n",
      "NO. 59 resnet.layer4.1.bn2.bias\n",
      "NO. 60 resnet.fc.weight\n",
      "NO. 61 resnet.fc.bias\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in p_encoder.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"NO.\", i, name)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4473f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,9,(5,10))\n",
    "b = torch.randint(0,9,(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1ee62c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat((a,b), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eed8db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.0\n",
    "def compute_return(rewards): \n",
    "    Returns = [0]\n",
    "    for i in range(len(rewards)-1, -1, -1): \n",
    "        print(rewards[i] + gamma * Returns[-1])\n",
    "        Returns.append(rewards[i] + gamma * Returns[-1])\n",
    "    Returns.reverse()\n",
    "    return Returns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ada139cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "rewards = [i for i in range(1, N+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd087f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf740fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "9.0\n",
      "12.0\n",
      "14.0\n",
      "15.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15.0, 14.0, 12.0, 9.0, 5.0]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_return(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a1f1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "71c1bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_state = [True, False, True, False, False] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8efa484",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = torch.tensor([i for i in range(len(env_state)) if env_state[i]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d57cda3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9782bee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ids:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "if ids.isEmpty():\n",
    "    print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "190be85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [[1,2,3], [4], [7,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68c90046",
   "metadata": {},
   "outputs": [],
   "source": [
    "v[1] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e3f153dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [], [7, 2]]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab75a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([0 for _ in range(5)]).to(device).reshape(5,1)\n",
    "v = torch.tensor([5 for _ in range(5)]).to(device).reshape(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fcbda7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
      "        [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
      "        [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
      "        [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
      "        [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "u = torch.cat([u,v], dim = 1)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4ac30d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "u[4] = torch.tensor([0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "19fe3bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "        [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "        [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "        [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21afd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_isaaclab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
